<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Alex Feldman</title>
    <description>Things I made, or things I wish I made.</description>
    <link>http://felday.info/</link>
    <atom:link href="http://felday.info/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Sat, 27 Aug 2016 20:54:44 -0400</pubDate>
    <lastBuildDate>Sat, 27 Aug 2016 20:54:44 -0400</lastBuildDate>
    <generator>Jekyll v3.1.6</generator>
    
      <item>
        <title>Computer Vision Course: Udacity with Aaron Bobick</title>
        <description>&lt;p&gt;This summer I learned a lot about computer vision from Aaron Bobick through his Udacity Course on the topic. He is a captivating teacher, even over video, and I want to highlight one of the most important lessons I picked up from the series.&lt;/p&gt;

&lt;p&gt;I didn’t code all the problems sets and I didn’t understand everything about Fourier transforms, but I internalized a broad lesson that serves me well.&lt;/p&gt;

&lt;p&gt;Take a look at &lt;a href=&quot;https://www.youtube.com/watch?v=8kiz9mgi1So&quot;&gt;this video&lt;/a&gt; from the course in which Bobick shows an optical illusion which I’ve seen a half dozen times. A block casts its shadow over a grid of white and gray tiles. It turns out that the white tile in shadow has the same color intensity as the gray tile on the side.&lt;/p&gt;

&lt;p&gt;I have always liked tricks like this and &lt;a href=&quot;http://giphy.com/gifs/3d-op-art-optical-illusion-3o7ZenrvPHmZEQLVkY&quot;&gt;gifs&lt;/a&gt; make for some of the illusions out there. Bobick’s video isn’t exceptional because he pulls a neat trick, but because he explains what is difficult in computer vision. It is so clear to the eye that that block is casting a shadow, but CV can’t make assumptions like that. A robust CV system must infer very complex ideas in order to understand even the most simple situations.&lt;/p&gt;

&lt;p&gt;Thinking about the unique elements in an image and what clues a computer could employ to understand an image - that is what I love about CV. That is what I love about Bobick’s course.&lt;/p&gt;

&lt;div id=&quot;_giphy_tv&quot;&gt;&lt;/div&gt;
&lt;script&gt;
    var _giphy_tv_tag=&quot;optical-illusion&quot;;
    var g = document.createElement(&#39;script&#39;); g.type = &#39;text/javascript&#39;; g.async = true;
    g.src = (&#39;https:&#39; == document.location.protocol ? &#39;https://&#39; : &#39;http://&#39;) + &#39;giphy.com/static/js/widgets/tv.js&#39;;
    var s = document.getElementsByTagName(&#39;script&#39;)[0]; s.parentNode.insertBefore(g, s);
&lt;/script&gt;

</description>
        <pubDate>Sat, 27 Aug 2016 00:00:00 -0400</pubDate>
        <link>http://felday.info/blog/2016/08/27/CV-Course.html</link>
        <guid isPermaLink="true">http://felday.info/blog/2016/08/27/CV-Course.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Crossword Puzzles</title>
        <description>&lt;p&gt;I’m terrible at crossword puzzles but maybe machine learning can save me. Every week my mother finishes the New York Times Magazine crossword and I’ve taken a few cracks at it myself. I love a good KenKen and nothing beats a Sudoku for airplane rides, but I can never seem to get the references that Will Shortz throws my way.&lt;/p&gt;

&lt;p&gt;There are plenty of &lt;a href=&quot;http://www.crosswordsolver.org/&quot;&gt;Crossword Solvers&lt;/a&gt; which can do searches from a dictionary file for words with known length and some letters, but I’m picturing something that does it all. With a big training set and great NLP it should be easy enough to implement. Watson did it with Jeopardy and crossword answers are much more structured than is that game. I don’t have the time now to build it myself but I’d love to see a program which can solve the Saturday NY Times crossword.&lt;/p&gt;

&lt;p&gt;IBM and other big companies are pushing the limits of NLP very quickly and this may be the perfect time to use that research to get some garden-variety tools.&lt;/p&gt;

&lt;p&gt;My program would have two components.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;For each word in the puzzle create a list of restrictions (word length and letter placement) on a dictionary file&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Use machine learning and word restrictions to generate possibilities. If above a threshold, accept the word&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;These would loop (or maybe coroutine) until I had a complete puzzle. With those at it’s core, I’m fairly sure this design would do well.&lt;/p&gt;

&lt;p&gt;If this already exists or if I oversimplified the process, shoot me an email! felday &lt;em&gt;at&lt;/em&gt; brandeis &lt;em&gt;dot&lt;/em&gt; edu.&lt;/p&gt;
</description>
        <pubDate>Tue, 23 Aug 2016 00:00:00 -0400</pubDate>
        <link>http://felday.info/blog/2016/08/23/Crossword-Solver.html</link>
        <guid isPermaLink="true">http://felday.info/blog/2016/08/23/Crossword-Solver.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Ball Tracking for Squash</title>
        <description>&lt;p&gt;A MATLAB Computer Vision program&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/aalllxx/Squash-Project&quot;&gt;GitHub repository&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;overview&quot;&gt;Overview&lt;/h2&gt;
&lt;p&gt;Ball tracking in sports has been around for over 15 years and I implemented a version that works for squash. I explain my process in depth in this post, but I figure I’ll give away the result at the top. (I’m really proud of it). Check out how the curves in the output match the ball path in the input.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Input:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://media.giphy.com/media/3o6Zt89eg01OUTaD16/giphy.gif&quot; alt=&quot;Animated Squash Clip&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Output:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/20CSBmj.jpg&quot; alt=&quot;Output image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The ball is hard to make out in the gif of the input video so I added a yellow highlight before posting this. It has nothing to do with my program.&lt;/p&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;With the Rio Olympics underway, everybody seems to be excited about odd sports. I got into squash last August and spent all year obsessed. I played squash, I watched squash, I tried to get my friends into squash. This summer, it didn’t take long to realize I wanted to create a program for squash, but the specifics were much harder to flesh out.&lt;/p&gt;

&lt;h2 id=&quot;inspiration&quot;&gt;Inspiration&lt;/h2&gt;

&lt;p&gt;I found two videos on Facebook that gave me my original direction and motivation. The first was of the German company &lt;a href=&quot;http://funwithballs.com/&quot;&gt;Fun With Balls GmbH&lt;/a&gt; and their &lt;a href=&quot;http://interactivesquash.com/&quot;&gt;Interactive Squash&lt;/a&gt; project. They project animated games onto the front wall of a squash court and detect where the ball hits. They support simple games like tic-tac-toe as well as training exercises which can test a player’s ability to hit a particular spot on the wall. I was certainly not aiming to create a project that user-oriented or marketable, but identifying where a ball hit the front wall remained a primary goal of mine for quite a while.&lt;/p&gt;

&lt;p&gt;The second video blew my mind entirely and motivated me to keep with sports oriented computer vision. &lt;a href=&quot;http://sportlogiq.com/&quot;&gt;SPORTLOGiQ&lt;/a&gt;, a Montreal based sports computer vision company,  made &lt;a href=&quot;https://vimeo.com/133304995&quot;&gt;this video&lt;/a&gt; showing off their hockey technology and it was on an entirely different level than what I had thought was possible. HawkEye, SportsVision, and others have made their own splashes in the industry, and maybe it is just excellent marketing, but SPORTLOGiQ seems far ahead.&lt;/p&gt;

&lt;p&gt;What’s so captivating about their product is not it’s beautiful UX design or perfect player/puck tracking. I was in awe of it’s ability to understand what was happening in a game. They track statistics like loose puck recoveries and can determine which players contribute to goals. That understanding comes at a higher level than tracking objects and I never considered that a machine could figure it out. I’ve always been interested in sports technology, be it first down lines, baseball pitch tracking, or tennis in/out decisions, but SPORTLOGiQ’s video gave me new inspiration.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Starting to program&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Early in development, I was overflowing with inspiration, but seriously lacked direction. My original goal was still to detect where on the front wall a ball hit, and by the time I had developed decent ball detection in each frame (more on that later), I was painfully aware of how hard it would be to pull that off in 2D.&lt;/p&gt;

&lt;p&gt;I had also been messing around extensively in MATLAB. This was my first time working in MATLAB and I was impressed with the documentation available on all built-in functions. My first real taste of computer vision came from reading the help articles on functions with input arguments I couldn’t understand. I remember struggling with the &lt;a href=&quot;http://www.mathworks.com/help/vision/examples/using-kalman-filter-for-object-tracking.html&quot;&gt;Kalman Filter&lt;/a&gt; for a day or two and slowly understanding the difference between detection and tracking.&lt;/p&gt;

&lt;p&gt;To keep at bay my growing anxiety that my project may fail, I binge-watched a  &lt;a href=&quot;https://www.udacity.com/course/introduction-to-computer-vision--ud810&quot;&gt;Udacity course on computer vision&lt;/a&gt; with Professor Aaron Bobick formerly of Georgia Tech. His course is excellent. I learned about &lt;a href=&quot;https://classroom.udacity.com/courses/ud810/lessons/3515968538/concepts/34851485780923#&quot;&gt;Fourier Transforms&lt;/a&gt;, and &lt;a href=&quot;https://classroom.udacity.com/courses/ud810/lessons/2965048666/concepts/29469186670923#&quot;&gt;stereo geometry&lt;/a&gt;, and a million other fascinating topics, but at the end of the day, none of it was really applicable to the basic tracking problem I was looking to solve.&lt;/p&gt;

&lt;p&gt;In my hunt for scholarly help I found &lt;strong&gt;&lt;a href=&quot;http://www.springer.com/us/book/9783319093956&quot;&gt;Computer Vision in Sports&lt;/a&gt;&lt;/strong&gt; (Springer International, 2014) which, after a week in interlibrary transit from the University of Wisconsin, changed my whole direction for the project.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Computer Vision in Sports&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;CV in Sports&lt;/em&gt; is a collection of scholarly papers published by a number of researchers on advances in CV as they apply to various sports. After drooling over the introductory chapter I had a handle on the four areas of focus the book explores.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Ball tracking&lt;/li&gt;
  &lt;li&gt;Player tracking&lt;/li&gt;
  &lt;li&gt;Determining what sport is being played&lt;/li&gt;
  &lt;li&gt;What is happening within a game&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The whole book is astounding, but as soon as I saw this image I knew what I was going to build.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/5ik9fWq.png&quot; alt=&quot;Clipping from CV in Sports&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Source: Computer Vision in Sports&lt;/em&gt;, p. 35&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;On to the code&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;That’s about all I the introduction I have to offer. I’ll note that I pushed aside most of my worries about time efficiency. My goal was to create a program which could produce the results I wanted without any other caveats. I didn’t care if it worked quickly or was especially user friendly, so long as it worked well. I’ll point out a few instances where I clearly chose very slow algorithms and something quicker might have been nearly as good.&lt;/p&gt;

&lt;p&gt;Finally, if you want a quick introduction to squash, &lt;a href=&quot;https://www.youtube.com/watch?v=3gQsAKZ71tU&quot;&gt;this video&lt;/a&gt; does a mediocre job of explaining the rules, but has good illustrations. Onward!&lt;/p&gt;

&lt;h2 id=&quot;blob-it-up---ball-detection&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Blob-It-Up&lt;/code&gt; - Ball detection&lt;/h2&gt;
&lt;p&gt;What I enjoyed most about this project and CV in general is the way they make me think about breaking down everyday tasks into clear sets of instructions. The way I thought about detecting the ball in each frame, one of the first tasks in the project, is a clear example of this.&lt;/p&gt;

&lt;p&gt;The first piece of code I wrote for this project was designed to use a built in MATLAB &lt;a href=&quot;https://en.wikipedia.org/wiki/Viola%E2%80%93Jones_object_detection_framework&quot;&gt;Viola Jones&lt;/a&gt; object detector. I would detect the ball in each frame by taking each frame and looking for a small, black circle - the ball. This, of course, didn’t work at all. Small black circles are about as hard to detect as objects come. The best MATLAB documentation I found was for self-driving car programs - moving cameras looking for consistent and unique stationary objects. It took me a few failures to implement one of those algorithms to realize how my task was unique.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://lewisdartnell.com/motion/motion_images/Anim_1.gif&quot; alt=&quot;Moving Box&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Source: LewisDartnell.com&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Like spotting camouflaged birds when they fly away, my squash ball was only distinct from background noise in that it moved. It didn’t just bounce around randomly either - it followed paths. A few weeks after figuring this out, &lt;em&gt;CV in Sports&lt;/em&gt; would give me the tools to quantify the motion, but when building my detector I was only thinking about the difference between frames.&lt;/p&gt;

&lt;p&gt;My first example of slow code is &lt;code class=&quot;highlighter-rouge&quot;&gt;toSmoothedDiff&lt;/code&gt;, the way I created a video of the difference between frames. I spent a long time tuning this code to work with my test clips. I used a GoPro wide angle shot at 720p and 120fps and attached the camera to the glass at the back of the court. With a different camera in a different position all of these tunings would need to be adjusted. This &lt;strong&gt;is not&lt;/strong&gt; a scaleable program. &lt;code class=&quot;highlighter-rouge&quot;&gt;toSmoothedDiff&lt;/code&gt; could certainly be optimized and made easier to modify, but I choose to keep it well tuned and left it as is. The only bit of efficiency I introduced at this stage was working with grayscale and then logical black and white images. I’ll discuss using color at the end of the post, but long story short, it’s not very useful.&lt;/p&gt;

&lt;p&gt;The hardest part about generating clean detections is that there is too much noise, especially around the players. Because of the camera placement, the ball can be close to camera and large, or speeding into the front wall and only a few pixels wide. Just for an idea of the scale, my blobs were between 100px&lt;sup&gt;2&lt;/sup&gt; and 750px&lt;sup&gt;2&lt;/sup&gt;. Limbs and racquets often split into odd shapes in the difference video and even when I sampled at 120fps the ball would stretch into two disconnected blobs when hit quickly. Even with my finely tuned difference video it was still not possible to reliably detect the ball in each frame.&lt;/p&gt;

&lt;p&gt;My solution to this problem is horribly inefficient and it pains me to think about. I took a second difference video with a four frame difference and used that help remove slower moving blobs. The result is a very clean image which allowed me to easily detect the ball.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://media.giphy.com/media/l2SpTmHEvaCRmYamA/giphy.gif&quot; alt=&quot;shoD1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Difference of one frame&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://media.giphy.com/media/3o6Ztd0iCk0O3SNhfy/giphy.gif&quot; alt=&quot;shoD2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Difference of four frames&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://media.giphy.com/media/3o6Zth2jI3MSl2FXXi/giphy.gif&quot; alt=&quot;noPeople&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Result of &lt;code class=&quot;highlighter-rouge&quot;&gt;noPeople&lt;/code&gt; with above as inputs&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Look at how much brighter the four frame difference video is, especially around the players. The biggest problem I had with detection was that racquets or limbs would often separate from the large &lt;em&gt;person&lt;/em&gt; blob and get detected as a possible ball. By subtracting at a further difference, I was able to more clearly figure out where the whole player was and exclude that when searching for the ball.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;noPeople&lt;/code&gt; was very hard to optimize properly, and &lt;code class=&quot;highlighter-rouge&quot;&gt;blobItUp&lt;/code&gt; only uses it in noisy frames with more than 2 detections, but in the noisiest sections it works wonders at cleaning up a frame. At the end of the day, though, I hope that in future versions I’ll do away with the two difference videos.&lt;/p&gt;

&lt;p&gt;Once I had well tuned difference videos the real challenge started. What unique characteristics does a squash ball have that noise or players do not? Through fine tuning of &lt;code class=&quot;highlighter-rouge&quot;&gt;blobItUp&lt;/code&gt; I was able to isolate objects of the right size, but I was still a long way away from generating paths.&lt;/p&gt;

&lt;p&gt;My tuning process was simple trial and error. I would change the size of my morphological dilation brush and minimum and maximum blob size. If no detections were found in a frame where there should be, I would redo the dilation with a larger brush. If too many detections were found, I would use &lt;code class=&quot;highlighter-rouge&quot;&gt;noPeople&lt;/code&gt; and the second difference video to figure out which detections could be ignored.&lt;/p&gt;

&lt;p&gt;At that point my detections were reliable and I was ready to solve my original problem - finding where on the front wall the ball made contact. A simple solution to this problem is possible with my two dimensional setup. When the ball changes direction and speed in a pixel on top of the front wall I could locate that point in the 2D space of the front wall. There are many problems with this setup and to do it right, I would need at least 2 cameras. In any case, without a setup to track the ball, only to detect it, my task was not feasible.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/dCz5Dps.png&quot; alt=&quot;Detections&quot; /&gt;
&lt;em&gt;All detections from &lt;code class=&quot;highlighter-rouge&quot;&gt;blobItUp&lt;/code&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;With accurate ball detection in ~85% of frames without total ball occlusion the results from &lt;code class=&quot;highlighter-rouge&quot;&gt;blobItUp&lt;/code&gt; are consistently excellent. I can practically draw the curves already! With this as a foundation, I turned to object tracking.&lt;/p&gt;

&lt;h2 id=&quot;layered-data-association&quot;&gt;Layered Data Association&lt;/h2&gt;
&lt;p&gt;The 2D ball tracking chapter of &lt;em&gt;CV in Sports&lt;/em&gt; described a three part process called Layered Data Association. For this section, looking at &lt;a href=&quot;https://github.com/aalllxx/Squash-Project&quot;&gt;my code&lt;/a&gt; is the most useful way to see how I implemented each element. Here I’ll try to explain the process in plain English&lt;/p&gt;

&lt;p&gt;Layered Data Association(as described in &lt;em&gt;CV in Sports&lt;/em&gt;) begins with a clip of a whole game of tennis with detections in each frame and outputs all of the paths from all of the rallies in the game. Each of the three levels works at a different level of abstraction as follows:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Candidate Level&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;generatePoints&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;generateTracklets&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;improveTracklets&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;This is the first abstraction away from detections. A game becomes a series of functions.&lt;/p&gt;

&lt;p&gt;I generate tracklets from detections and check a circular window around each detection for other detections. If in the previous and following frames there are detections within a radius, a tracklet is formed. The three points become supports, and a second order function is fitted.&lt;/p&gt;

&lt;p&gt;Tracklets are iteratively improved. I predict where the next detection should be based on the model in each tracklet and if detections lie within a threshold of that point, it is added to the tracklet and the fitted function is updated. This iteratively repeats until the overall fit stops improving, or no new supports are found.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Tracklet Level&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;connectTracklets&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;In this process shortest paths are found between each tracklet generated above. This abstracts away from individual functions and pieces together whole rallies.&lt;/p&gt;

&lt;p&gt;If the models were not similar I extended temporally adjacent curves to their intersection and drew it out. Due to occlusion or racquet noise, detections near players are typically worse. Because curves typically end around players (when they hit the ball), extending curves this way is especially important. I drew those sections in yellow in the original output image.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Path Level&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Shortest paths are found between all tracklets, not just adjacent ones. This shows which tracklets are connected (in a single rally) and which are distinct. It abstracts a third time and builds an entire game from a collection of rallies.&lt;/p&gt;

&lt;p&gt;I didn’t implement Path Level Association but I certainly intend to in the future. I hope to write more about it then.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Endpoint/Midpoint Curves vs MATLAB fitObjects&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;CV in Sports&lt;/em&gt; was my guide for implementing Layered Data Association and it steered me in the right direction time and time again. The one decision where I really took a different route than the book is how I created my models.&lt;/p&gt;

&lt;p&gt;The book writes out the basics physics equations deriving acceleration, velocity, and position that I learned in high school.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/rlXxehY.png&quot; alt=&quot;Equations&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Equations from CV in Sports. &lt;strong&gt;p&lt;/strong&gt; is position, &lt;strong&gt;v&lt;/strong&gt; is velocity, &lt;strong&gt;a&lt;/strong&gt; is acceleration, &lt;strong&gt;k&lt;/strong&gt; is frame.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;I had coded my curves using each tracklets’ first and last supports and by choosing a middle support between the two. These equations work alright when there are a small number of points, but because they ignore all internal supports they are a bad choice for modeling long paths. If the ball path and all detections were perfectly regular a function based on three points would work, but with even a small amount of deviation the models produced are poor. Once I made the switch to using MATLAB’s built in &lt;code class=&quot;highlighter-rouge&quot;&gt;fit()&lt;/code&gt; function my results improved dramatically.&lt;/p&gt;

&lt;p&gt;The only downside was that whereas I had been storing values in [xValue, yValue] arrays, I needed two fit objects stored in a struct for my tracklet models. One function mapped time to X position and the other mapped time to Y position. Position was dependent and frame number was independent.&lt;/p&gt;

&lt;p&gt;Again, for all the details of my implementation, please take a look at &lt;a href=&quot;https://github.com/aalllxx/Squash-Project&quot;&gt;the code&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;explaining-my-output&quot;&gt;Explaining my output&lt;/h2&gt;
&lt;p&gt;After discussing my implementation it’s time to explain the image I posted at the start of this post. There are dots and lines in four colors and it’s not so intuitive to read.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/20CSBmj.jpg&quot; alt=&quot;Output image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Black dots&lt;/strong&gt;
Black dots represent all detections from my candidate level association. They are primarily in a line around the path of the ball, but are also scattered around the court.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Red dots&lt;/strong&gt;
Red dots are detections which had supports on either side. I formed tracklets with models from these.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Blue curves&lt;/strong&gt;
Blue curves show tracklets which had more than 4 supports. &lt;code class=&quot;highlighter-rouge&quot;&gt;improveTracklets&lt;/code&gt; takes each tracklet with supports and scoops up nearby detections which are within a threshold of where the tracklets model predicts. It adds these points to its own supports while deleting them from their old tracklet. If a tracklet has zero supports it is considered dead. In this way, longer tracklets grow and form single functions along a path.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Yellow curves&lt;/strong&gt;
Yellow curves are extensions of a tracklet’s model to the intersection with the neighboring tracklet. This is especially important because the racquet head will always occlude the ball when contact is made.
When the intersection is outside both curves (like in the long top right example) both curves are drawn. When the intersection is within one curve (bottom left) only the extension from one curve is drawn. In this case the curves don’t line up because the ball traveled across the player’s body and was occluded from view.&lt;/p&gt;

&lt;p&gt;I was surprised by how true the ball travels to 2nd order (constant acceleration) polynomial curves. In the top-right section of the output there are long yellow extensions. My blue curves end 275px and 75px from the predicted intersection and the error, which I measured by hand from the actual frame of contact, was 20px. For such a long distance I am happy with that margin of error. With better tuning to my &lt;code class=&quot;highlighter-rouge&quot;&gt;scoopItUp&lt;/code&gt; code I’m sure that error would come down.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;It’s far from perfect&lt;/strong&gt;
My program works fairly well, but by taking a close look at a second clip I’ll can show some areas that desperately need improvement.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://i.giphy.com/3o6Zt2HBg6ECJP0dvW.gif&quot; alt=&quot;Second Clip Highlighted&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;A second clip I worked with. Highlights added by hand before posting to blog.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/xOYnt7m.png&quot; alt=&quot;Second Clip Output&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Output of second clip&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The first thing you’ll notice is my error on the forehand volley drop. I need to be quicker to the ball and put it away.&lt;/p&gt;

&lt;p&gt;After getting over that, look at how the output is segmented in strange places. I don’t really know why my blue tracklets are broken up in those places. That could be a small issue with how I tuned &lt;code class=&quot;highlighter-rouge&quot;&gt;improveTracklets&lt;/code&gt; or it could indicate some larger bug. In any case, &lt;code class=&quot;highlighter-rouge&quot;&gt;connectTracklets&lt;/code&gt; is sometimes able to compensate for this problem and draw yellow lines between the disconnected segments.&lt;/p&gt;

&lt;p&gt;The next issue has more to do with how I created this output. &lt;code class=&quot;highlighter-rouge&quot;&gt;improveTracklets&lt;/code&gt; is meant to iteratively run the &lt;code class=&quot;highlighter-rouge&quot;&gt;scoopUp&lt;/code&gt; method, but I didn’t fully implement the loop. In theory, tracklets should be improved until the next iteration doesn’t find any new supports or the model starts to fit the supports worse than the last iteration. I would do this by checking &lt;code class=&quot;highlighter-rouge&quot;&gt;numSupports&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;meanDistance&lt;/code&gt; after each iteration, but the real trouble comes in determining what threshold to use at each iteration.&lt;/p&gt;

&lt;p&gt;When I made this output I ran two iterations of &lt;code class=&quot;highlighter-rouge&quot;&gt;scoopUp&lt;/code&gt;, first with a distance threshold (how far a point can be from a prediction) of 5px and then of 3px. I tried it with smaller and larger thresholds and both produced worse results. I know how to implement this aspect, but ran out of time in the summer. For now, this all needs to be done manually. It also means that &lt;code class=&quot;highlighter-rouge&quot;&gt;doItAll&lt;/code&gt;, my function which runs all the pieces in order, will not produce results as solid as doing it by hand and tweaking the threshold.&lt;/p&gt;

&lt;p&gt;At the end of the day, this is a strong proof-of-concept, but needs lots of work to do anything useful.&lt;/p&gt;

&lt;h2 id=&quot;other-thoughts&quot;&gt;Other thoughts&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;A rant about OOP in MATLAB&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;I’ve done most of my serious programming in Java so once I had a clear idea of what I needed, I transitioned straight into an Object-Oriented design. MATLAB seriously disappoints in its OOP practicality, and if I was doing this again I would certainly keep everything procedural. In essence I did make all my methods procedural by passing index values to my class methods and returning my modified elements from those methods. Passing by reference is not simple in MATLAB.&lt;/p&gt;

&lt;p&gt;The only real difference between my implementation and a purely procedural one is that MATLAB displays the values of 1 dimensional structs when inspecting variables, but does not display class attributes. Passing values was a small nuisance, but the poor debugger design frustrated me to no end.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Why squash is different&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;I mentioned at the top of this post that ball tracking, even real-time tracking, has been around for a long time. This program is far from groundbreaking. That doesn’t much bother me (it’s new to me), but even if I was upset to be recreating an ancient technology, I could take solace in some of the unique aspects of squash.&lt;/p&gt;

&lt;p&gt;My second clip shows this to some degree, but squash in general, and especially professional squash, is very chaotic. Watch &lt;a href=&quot;https://www.youtube.com/watch?v=IpApHbJpCy8&quot;&gt;this clip&lt;/a&gt; and pay attention to the dramatic changes in ball speed, the odd angles on boasts, the tightness of shots to the side walls, the reflections in the glass, etc. Whereas tennis has long and clean curves, squash rallies are all over the place. I am very happy that my program can detect strange angles and instant changes of speed.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;What I learned&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;MATLAB&lt;/li&gt;
  &lt;li&gt;CV / Image processing&lt;/li&gt;
  &lt;li&gt;Working on a long-term project&lt;/li&gt;
  &lt;li&gt;How to explain a CS project to friends&lt;/li&gt;
  &lt;li&gt;Markdown&lt;/li&gt;
  &lt;li&gt;GitHub&lt;/li&gt;
  &lt;li&gt;Blogging with Jekyll&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;future-plans&quot;&gt;Future plans&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Player tracking&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;After tracking the ball, tracking players feels like the next natural step. There are already a number of programs which accomplish this. In 2001, Pers et al. created a &lt;a href=&quot;https://www.researchgate.net/profile/Stanislav_Kovacic/publication/3905802_A_low-cost_real-time_tracker_of_live_sport_events/links/0c960533ac2da56f04000000.pdf&quot;&gt;A Low-Cost Real-Time Tracker of Live Sport Events&lt;/a&gt; and more recently, two undergrads at the University of Pennsylvania put together &lt;a href=&quot;https://www.cis.upenn.edu/current-students/undergraduate/courses/documents/HonorspaperforEAS499_Wu_Judd.pdf&quot;&gt;a program&lt;/a&gt; which does just that with a single camera above the court. Like my 2D ball tracking, that technology is interesting, but by itself mostly useless.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Stereo vision&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;I literally dream of stereo tracking. I think about how adding a second camera to my setup would solve my biggest problems and pave the way to new and useful functionality. All of the big innovations which I want to see for squash tracking need 3D.&lt;/p&gt;

&lt;p&gt;Drawing the path of a squash ball is nice, but is hardly useful in any practical way. By introducing stereo footage, video I could make a 3D hull rendering of the squash court. I would know where on each wall the ball bounced and the speed of the ball at each frame. Adding a second camera would also help with the regular occlusions that a single camera has trouble with.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Use color (or maybe not)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;My program totally ignores color and immediately converts videos to grayscale. In my implementation that is fine, but for player detection or to detect reflections on glass courts, color could be useful. In general, what I’ve seen is that detection isn’t very difficult in a controlled environment like a squash court. The marginal benefits of color are likely not ever going to be worth the triple computing time.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Better camera positioning&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This was my first time using a GoPro and I was shocked with the ease of use and quality of video produced. I clipped a tiny box to the back wall and it recorded in HD at 120fps. In previous setups I had been hanging tripods off of railings and attaching cameras with large lenses to them. Even then, the field of view and frame rate didn’t compare with the GoPro’s.&lt;/p&gt;

&lt;p&gt;The GoPro’s wide angle shot did cause problems for my ball detection and curve fitting. In my main test clip most of the action took place in the front of the court and when I tested rallies that were played further back they were much less smooth. This is partially because the ball changes size dramatically between the front and back of the court. Changes in position are also more extreme when closer to the camera and that causes the ball path to deviate from perfect 2nd order polynomials. Using a camera position similar to broadcast would help my program perform.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://i.giphy.com/l2Sqi70EikLX7kt1u.gif&quot; alt=&quot;zoomed camera&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Source: PSA Squash TV&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Player skeleton tracking&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Like Microsoft’s Kinect showed, tracking a human skeletal structure is a feasible and effective way to track a person’s movements. Implementing this for a squash player could reveal interesting information about the technique of squash players. It could be used for professional player statistics or for analysis and coaching.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://answers.unrealengine.com/storage/temp/18510-kinect_bones.gif&quot; alt=&quot;skeleton tracking&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Source: answers.unrealengine.com&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Big data&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;In a fully featured system I would be sure to track as many statistics as possible. A squash tracking system would be the total package if it could record all of the information I mention above. I’m excited to think about how huge amounts of data could change how players, especially amateur players, are coached. I’d also like to see quantitative data on how &lt;a href=&quot;https://www.youtube.com/watch?v=p1YhN8WTStI&quot;&gt;Egyptian&lt;/a&gt; and &lt;a href=&quot;https://www.youtube.com/watch?v=HtwckCfSIHU&quot;&gt;British&lt;/a&gt; play styles are different. A program could even learn which shots a particular player likes to use in different scenarios.&lt;/p&gt;

&lt;p&gt;The sky will be the limit when it becomes easy to measure shot selection, racquet speed, and quantify technique. More than inclusion in the  olympics or improved racquet design, I want to see squash as a pioneer in computer vision. I hope I’m not the only one.&lt;/p&gt;
</description>
        <pubDate>Tue, 16 Aug 2016 16:00:00 -0400</pubDate>
        <link>http://felday.info/projects/2016/08/16/Squash-Ball-Tracking.html</link>
        <guid isPermaLink="true">http://felday.info/projects/2016/08/16/Squash-Ball-Tracking.html</guid>
        
        
        <category>projects</category>
        
      </item>
    
      <item>
        <title>Space Carving</title>
        <description>&lt;p&gt;Thinking about Space Carving got me thinking about 3D modeling in a different way than I had before. It gave me a good model to think about how 3D works.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=cGs90KF4oTc&quot;&gt;&lt;img src=&quot;http://img.youtube.com/vi/cGs90KF4oTc/0.jpg&quot; alt=&quot;Space Carving Vid&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Tue, 16 Aug 2016 00:00:00 -0400</pubDate>
        <link>http://felday.info/blog/2016/08/16/Space-Carving.html</link>
        <guid isPermaLink="true">http://felday.info/blog/2016/08/16/Space-Carving.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>SPORTLOGiQ Hockey</title>
        <description>&lt;p&gt;When I saw this video I was inspired to jump into computer vision in sports and build my &lt;a href=&quot;http://felday.info/projects/2016/08/16/Squash-Ball-Tracking.html&quot;&gt;squash ball tracking program&lt;/a&gt;. I love how the program can determine loose puck recoveries, who contributed to goals, and other high level elements of a game.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://vimeo.com/133304995&quot;&gt;&lt;img src=&quot;http://i.imgur.com/WDa56aS.png&quot; alt=&quot;SPORTLOGiQ Vid&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Tue, 16 Aug 2016 00:00:00 -0400</pubDate>
        <link>http://felday.info/blog/2016/08/16/SPORTLOGiQ-Hockey.html</link>
        <guid isPermaLink="true">http://felday.info/blog/2016/08/16/SPORTLOGiQ-Hockey.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Reinforced Dirt</title>
        <description>&lt;p&gt;I have been on a civil engineering kick recently. This got me thinking about the infrastructure I see every day.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=0olpSN6_TCc&quot;&gt;&lt;img src=&quot;http://img.youtube.com/vi/0olpSN6_TCc/0.jpg&quot; alt=&quot;Reinforced Dirt Vid&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Tue, 16 Aug 2016 00:00:00 -0400</pubDate>
        <link>http://felday.info/blog/2016/08/16/Reinforced-Dirt.html</link>
        <guid isPermaLink="true">http://felday.info/blog/2016/08/16/Reinforced-Dirt.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>MIT Interactive Dynamic Video</title>
        <description>&lt;p&gt;This project uses video of almost still objects and examines the small vibrations in the objects to learn about how they move. It’s very cool.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=4f09VdXex3A&quot;&gt;&lt;img src=&quot;http://img.youtube.com/vi/4f09VdXex3A/0.jpg&quot; alt=&quot;MIT Interactive Dynamic Vid&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Tue, 16 Aug 2016 00:00:00 -0400</pubDate>
        <link>http://felday.info/blog/2016/08/16/MIT-Dynamic-Video.html</link>
        <guid isPermaLink="true">http://felday.info/blog/2016/08/16/MIT-Dynamic-Video.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Handheld CNC Router</title>
        <description>&lt;p&gt;&lt;a href=&quot;http://www.shapertools.com/&quot;&gt;Shaper Tools&lt;/a&gt; has a handheld CNC router in the works. What I love most in this video is the contrast in size between the old mill and the new handheld tool.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=q8GFpSCK6Jk&quot;&gt;&lt;img src=&quot;http://img.youtube.com/vi/q8GFpSCK6Jk/0.jpg&quot; alt=&quot;Handheld Router Vid&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Tue, 16 Aug 2016 00:00:00 -0400</pubDate>
        <link>http://felday.info/blog/2016/08/16/Handheld-CNC-Router.html</link>
        <guid isPermaLink="true">http://felday.info/blog/2016/08/16/Handheld-CNC-Router.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Discrete Cosine Transform</title>
        <description>&lt;p&gt;This was the first time I thought about images as anything other than pixels.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=Q2aEzeMDHMA&quot;&gt;&lt;img src=&quot;http://img.youtube.com/vi/Q2aEzeMDHMA/0.jpg&quot; alt=&quot;Discrete Cosine T Vid&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Tue, 16 Aug 2016 00:00:00 -0400</pubDate>
        <link>http://felday.info/blog/2016/08/16/DCT.html</link>
        <guid isPermaLink="true">http://felday.info/blog/2016/08/16/DCT.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
  </channel>
</rss>
